#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YouTube-–ø–∞—Ä—Å–µ—Ä: Shorts + –æ–±—ã—á–Ω—ã–µ —Ä–æ–ª–∏–∫–∏, –±–µ–∑ live/upcoming.
–°—á–∏—Ç—ã–≤–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (col A) –∏ –∏—Å—Ö–æ–¥–Ω—ã–µ URL (col J) –∏–∑ Google Sheets –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞—Ç–Ω–æ –≤ –ª–∏—Å—Ç "Results".
–ü—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Å –º–µ—Å—Ç–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —á–µ—Ä–µ–∑ shelve.
–ü—Ä–∏ –∏—Å—á–µ—Ä–ø–∞–Ω–∏–∏ –∫–≤–æ—Ç—ã –≤—Å–µ—Ö –∫–ª—é—á–µ–π –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç —É–∂–µ —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.
–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ BATCH_SIZE –∫–ª—é—á–µ–π.
"""
import os
import sys
import shelve
import time
import logging
import socket
from pathlib import Path
from datetime import datetime, timezone

import pandas as pd
import isodate
from langdetect import detect, LangDetectException
from dotenv import load_dotenv, dotenv_values
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from google.oauth2 import service_account

# ‚îÄ‚îÄ‚îÄ Logging ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s %(levelname)s %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# ‚îÄ‚îÄ‚îÄ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (–∏–∑ .env) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º –ø—É—Ç—å –∫ .env —Ä—è–¥–æ–º —Å–æ —Å–∫—Ä–∏–ø—Ç–æ–º –∏ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
env_path = Path(__file__).parent / ".env"
if not env_path.exists():
    logger.error(f"‚ùå .env —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏ {env_path}")
    sys.exit(1)

load_dotenv(dotenv_path=env_path, override=True)
SHEET_ID = os.getenv("SHEET_ID")
logger.info(f"üö© Loaded SHEET_ID from {env_path}: {SHEET_ID}")

KEYWORDS_SHEET       = os.getenv("KEYWORDS_SHEET", "Keywords")
RESULTS_SHEET        = os.getenv("RESULTS_SHEET", "Results")
SERVICE_ACCOUNT_JSON = os.getenv("SERVICE_ACCOUNT_JSON")
NUM_RESULTS          = int(os.getenv("NUM_RESULTS", 10))
REGION               = os.getenv("REGION", "US")
MAX_PAGES            = int(os.getenv("MAX_PAGES", 1))
OUTPUT_CSV           = os.getenv("OUTPUT_CSV", "yt_results.csv")
BATCH_SIZE           = int(os.getenv("BATCH_SIZE", 50))

if MAX_PAGES < 1:
    sys.exit("‚ùå MAX_PAGES –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å ‚â• 1")

# ‚îÄ‚îÄ‚îÄ Google Sheets API ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
SCOPES = ['https://www.googleapis.com/auth/spreadsheets']
creds_sheets = service_account.Credentials.from_service_account_file(
    SERVICE_ACCOUNT_JSON, scopes=SCOPES
)
sheets_service = build(
    'sheets', 'v4',
    credentials=creds_sheets,
    cache_discovery=False
)

# ‚îÄ‚îÄ‚îÄ –•—Ä–∞–Ω–∏–ª–∏—â–µ –∫–µ—à–∞ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
CACHE = shelve.open("yt_cache.db")

# ‚îÄ‚îÄ‚îÄ –û—à–∏–±–∫–∞ –∏—Å—á–µ—Ä–ø–∞–Ω–∏—è –∫–≤–æ—Ç—ã –≤—Å–µ—Ö –∫–ª—é—á–µ–π ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
class QuotaExceededAllKeys(Exception):
    """–í—Å–µ –∫–ª—é—á–∏ YouTube API –∏—Å—á–µ—Ä–ø–∞–ª–∏ –∫–≤–æ—Ç—É"""
    pass

# ‚îÄ‚îÄ‚îÄ –ö–ª–∞—Å—Å—ã –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è API-–∫–ª—é—á–∞–º–∏ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
class APIKey:
    def __init__(self, key: str):
        self.key = key
        self.service = build(
            "youtube", "v3",
            developerKey=key,
            cache_discovery=False
        )
        self.used_units = 0
        self.active = True

class KeyManager:
    def __init__(self, keys: list[str]):
        self.keys = [APIKey(k) for k in keys]
        self.index = 0

    def get_key(self) -> APIKey:
        n = len(self.keys)
        for _ in range(n):
            api = self.keys[self.index]
            self.index = (self.index + 1) % n
            if api.active:
                return api
        raise QuotaExceededAllKeys()

    def deactivate(self, api: APIKey):
        api.active = False
        logger.warning(f"–î–µ–∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω –∫–ª—é—á: {api.key}")

    def record(self, api: APIKey, units: int):
        api.used_units += units
        logger.info(f"–ö–ª—é—á {api.key}: —Ä–∞—Å—Ö–æ–¥ {units} units (–∏—Ç–æ–≥–æ {api.used_units})")

    def execute(self, fn, units=0, backoff_max=3):
        attempt = 0
        while True:
            api = self.get_key()
            try:
                resp = fn(api.service).execute()
                used = units(resp) if callable(units) else units
                self.record(api, used)
                return resp
            except HttpError as e:
                err_str = str(e)
                if 'quotaExceeded' in err_str or 'dailyLimitExceeded' in err_str:
                    self.deactivate(api)
                    continue
                if 'rateLimitExceeded' in err_str:
                    if attempt < backoff_max:
                        delay = 2 ** attempt
                        logger.warning(
                            f"Rate limitExceeded –Ω–∞ –∫–ª—é—á–µ {api.key}, –∂–¥—É {delay}s (–ø–æ–ø—ã—Ç–∫–∞ {attempt+1})"
                        )
                        time.sleep(delay)
                        attempt += 1
                        continue
                    else:
                        self.deactivate(api)
                        continue
                logger.error(f"Unexpected HttpError –Ω–∞ –∫–ª—é—á–µ {api.key}: {e}")
                raise
            except (ConnectionResetError, socket.error) as e:
                if attempt < backoff_max:
                    delay = 2 ** attempt
                    logger.warning(
                        f"Connection error –Ω–∞ –∫–ª—é—á–µ {api.key}: {e}, –∂–¥—É {delay}s (–ø–æ–ø—ã—Ç–∫–∞ {attempt+1})"
                    )
                    time.sleep(delay)
                    attempt += 1
                    continue
                else:
                    self.deactivate(api)
                    continue

# ‚îÄ‚îÄ‚îÄ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–ª—é—á–µ–π YouTube API ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
raw_keys = os.getenv("YT_API_KEYS") or dotenv_values(env_path).get("YT_API_KEYS", "")
KEYS = [k.strip() for k in raw_keys.split(",") if k.strip()]
if not KEYS:
    sys.exit("‚ùå –ù–µ—Ç API-–∫–ª—é—á–µ–π (YT_API_KEYS).")
logger.info(f"üîë –ù–∞–π–¥–µ–Ω–æ {len(KEYS)} –∫–ª—é—á–µ–π")
key_manager = KeyManager(KEYS)

VIDEO_PARTS = "snippet,contentDetails,status,player,statistics"

# ‚îÄ‚îÄ‚îÄ –£—Ç–∏–ª–∏—Ç—ã ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def iso2hms(iso: str):
    if not iso:
        return "", 0
    td = isodate.parse_duration(iso)
    s = int(td.total_seconds())
    h, r = divmod(s, 3600)
    m, sec = divmod(r, 60)
    return f"{h:02d}:{m:02d}:{sec:02d}", s

def fmt_age(pub: str):
    if not pub:
        return ""
    dt = datetime.fromisoformat(pub.replace('Z', '+00:00'))
    d = (datetime.now(timezone.utc) - dt).days
    y, rem = divmod(d, 365)
    mo = rem // 30
    return f"{y} years {mo} months" if y else f"{mo} months"

def safe_detect(txt: str):
    try:
        return detect(txt) if txt.strip() else ""
    except LangDetectException:
        return ""

# ‚îÄ‚îÄ‚îÄ –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤ Google Sheets –∏ CSV ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def append_to_sheets_with_retry(service, spreadsheet_id, sheet_range, values,
                                max_retries=5, base_delay=1):
    for attempt in range(1, max_retries+1):
        try:
            service.spreadsheets().values().append(
                spreadsheetId=spreadsheet_id,
                range=sheet_range,
                valueInputOption='RAW',
                body={'values': values}
            ).execute()
            logger.info("‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–ø–∏—Å–∞–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ Google Sheets")
            return True
        except (HttpError, ConnectionResetError, socket.error) as e:
            delay = base_delay * 2**(attempt-1)
            logger.warning(
                f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ {attempt}/{max_retries} –∑–∞–ø–∏—Å–∏ –≤ Sheets —É–ø–∞–ª–∞: {e}. –ñ–¥—ë–º {delay}s."
            )
            time.sleep(delay)
    logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –≤ Google Sheets –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫")
    return False

def save_csv_with_retry(df: pd.DataFrame, path: str, max_retries=3, base_delay=1):
    for attempt in range(1, max_retries+1):
        try:
            df.to_csv(path, index=False)
            logger.info(f"‚úÖ CSV —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {path}")
            return True
        except Exception as e:
            delay = base_delay * 2**(attempt-1)
            logger.warning(
                f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ {attempt}/{max_retries} —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è CSV —É–ø–∞–ª–∞: {e}. –ñ–¥—ë–º {delay}s."
            )
            time.sleep(delay)
    logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å CSV –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫")
    return False

def append_csv_batch(df: pd.DataFrame, path: str, max_retries=3, base_delay=1) -> bool:
    """–î–æ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç DataFrame –≤ CSV, —Å–æ–∑–¥–∞–≤–∞—è —Ñ–∞–π–ª —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."""
    p = Path(path)
    header = not p.exists()
    for attempt in range(1, max_retries+1):
        try:
            df.to_csv(path, index=False, header=header, mode='a')
            logger.info(f"‚úÖ CSV –±–∞—Ç—á —Å–æ—Ö—Ä–∞–Ω—ë–Ω ({len(df)} —Å—Ç—Ä–æ–∫): {path}")
            return True
        except Exception as e:
            delay = base_delay * 2**(attempt-1)
            logger.warning(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ {attempt}/{max_retries} –¥–æ–∑–∞–ø–∏—Å–∏ CSV —É–ø–∞–ª–∞: {e}. –ñ–¥—ë–º {delay}s.")
            time.sleep(delay)
    logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–∑–∞–ø–∏—Å–∞—Ç—å CSV –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫")
    return False

# ‚îÄ‚îÄ‚îÄ –ü–æ–∏—Å–∫ YouTube –≤–∏–¥–µ–æ –ø–æ –∫–ª—é—á—É ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def search_once(keyword: str, input_url: str) -> list:
    rows, token, page = [], None, 0
    while len(rows) < NUM_RESULTS and page < MAX_PAGES:
        page += 1
        sk = f"S:{keyword}:{REGION}:{token or ''}"
        if sk in CACHE:
            sr = CACHE[sk]
        else:
            sr = key_manager.execute(
                lambda svc: svc.search().list(
                    q=keyword,
                    part="id",
                    type="video",
                    order="relevance",
                    regionCode=REGION,
                    maxResults=min(50, NUM_RESULTS - len(rows)),
                    pageToken=token or "",
                    safeSearch="none"
                ),
                units=100
            )
            CACHE[sk] = sr
        vids = [it.get('id', {}).get('videoId') for it in sr.get('items', []) if it.get('id', {}).get('videoId')]
        if not vids:
            break
        vk = f"V:{','.join(vids)}"
        if vk in CACHE:
            vr = CACHE[vk]
        else:
            vr = key_manager.execute(
                lambda svc: svc.videos().list(
                    id=",".join(vids),
                    part=VIDEO_PARTS
                ),
                units=lambda resp: len(resp.get('items', []))
            )
            CACHE[vk] = vr
        cids = list({it['snippet']['channelId'] for it in vr.get('items', [])})
        amap = {}
        if cids:
            ck = f"C:{','.join(cids)}"
            if ck in CACHE:
                ch = CACHE[ck]
            else:
                ch = key_manager.execute(
                    lambda svc: svc.channels().list(
                        part="snippet",
                        id=",".join(cids)
                    ),
                    units=1
                )
                CACHE[ck] = ch
            amap = {c['id']: c['snippet']['thumbnails']['default']['url'] for c in ch.get('items', [])}
        for it in vr.get('items', []):
            sn = it.get('snippet', {})
            if sn.get('liveBroadcastContent') in {'live', 'upcoming'}:
                continue
            det = it.get('contentDetails', {})
            dur_str, dur_s = iso2hms(det.get('duration', ''))
            st = it.get('status', {})
            stats = it.get('statistics', {})
            author = sn.get('channelTitle', '')
            avatar = amap.get(sn.get('channelId', ''), '')
            if sn.get('defaultAudioLanguage'):
                ls, lang = 'audio', sn['defaultAudioLanguage']
            elif sn.get('defaultLanguage'):
                ls, lang = 'default', sn['defaultLanguage']
            else:
                ls, lang = 'detect', safe_detect(sn.get('title', '') + ' ' + sn.get('description', '')) or 'unknown'
            lic = st.get('license', '')
            emb = st.get('embeddable', False)
            allowed = emb and lic == 'creativeCommon'
            rows.append([
                keyword, input_url, it['id'], sn.get('title', ''), sn.get('description', ''),
                lang, ls, 'short' if dur_s < 60 else 'video',
                dur_str, dur_s, fmt_age(sn.get('publishedAt', '')), author, avatar,
                stats.get('viewCount', ''), stats.get('likeCount', ''), stats.get('dislikeCount', ''),
                emb, lic, allowed,
                it.get('player', {}).get('embedHtml', f"<iframe src=\"https://www.youtube.com/embed/{it['id']}\" allowfullscreen></iframe>")
            ])
        token = sr.get('nextPageToken') or None
    return rows

# ‚îÄ‚îÄ‚îÄ –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
r1 = sheets_service.spreadsheets().values().get(
    spreadsheetId=SHEET_ID,
    range=f"{KEYWORDS_SHEET}!A2:A"
).execute()
r2 = sheets_service.spreadsheets().values().get(
    spreadsheetId=SHEET_ID,
    range=f"{KEYWORDS_SHEET}!J2:J"
).execute()
keywords = [r[0] for r in r1.get('values', [])]
input_urls = [r[0] for r in r2.get('values', [])]

prog = shelve.open('progress.db')
start = prog.get('last_index', 0)
all_res = []
batch_res = []

try:
    for idx in range(start, len(keywords)):
        kw = keywords[idx]
        input_url = input_urls[idx] if idx < len(input_urls) else ''
        logger.info(f"üîç [{idx}] {kw}")
        res = search_once(kw, input_url)

        all_res.extend(res)
        batch_res.extend(res)
        prog['last_index'] = idx + 1

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±–∞—Ç—á–∞ –∫–∞–∂–¥—ã–µ BATCH_SIZE –∫–ª—é—á–µ–π
        if (idx + 1 - start) % BATCH_SIZE == 0:
            df_batch = pd.DataFrame(batch_res, columns=[
                'keyword','input_url','videoId','title','description','language','language_source',
                'video_type','duration','duration_seconds','age','author','author_avatar',
                'view_count','like_count','dislike_count','embeddable','license',
                'allowed_on_third_party','iframe'
            ])
            append_csv_batch(df_batch, OUTPUT_CSV)
            append_to_sheets_with_retry(
                sheets_service,
                SHEET_ID,
                f"{RESULTS_SHEET}!A2",
                batch_res
            )
            logger.info(f"üîÑ –ë–∞—Ç—á –∏–∑ {len(batch_res)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –ø–æ—Å–ª–µ {(idx+1-start)} –∫–ª—é—á–µ–π")
            batch_res = []

except QuotaExceededAllKeys:
    logger.warning("‚ö†Ô∏è –í—Å–µ –∫–ª—é—á–∏ –∏—Å—á–µ—Ä–ø–∞–ª–∏ –∫–≤–æ—Ç—É, –∑–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É")
finally:
    prog.close()
    CACHE.close()

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Å—Ç–∞—Ç–æ–∫ –±–∞—Ç—á–∞ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
if batch_res:
    df_batch = pd.DataFrame(batch_res, columns=[
        'keyword','input_url','videoId','title','description','language','language_source',
        'video_type','duration','duration_seconds','age','author','author_avatar',
        'view_count','like_count','dislike_count','embeddable','license',
        'allowed_on_third_party','iframe'
    ])
    append_csv_batch(df_batch, OUTPUT_CSV)
    append_to_sheets_with_retry(
        sheets_service,
        SHEET_ID,
        f"{RESULTS_SHEET}!A2",
        batch_res
    )
    logger.info(f"üîÑ –§–∏–Ω–∞–ª—å–Ω—ã–π –±–∞—Ç—á –∏–∑ {len(batch_res)} —Å—Ç—Ä–æ–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω")

# –ò—Ç–æ–≥–æ–≤—ã–π —Ä–∞—Å—Ö–æ–¥ –∫–≤–æ—Ç—ã
total_units = sum(api.used_units for api in key_manager.keys)
logger.info(f"‚ÑπÔ∏è –í—Å–µ–≥–æ —Ä–∞—Å—Ö–æ–¥: {total_units} units")
